{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\rdesa\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import InputLayer, Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2)\n",
      "(2000,)\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "DNAData = pd.read_csv(\"data.csv\")\n",
    "DNANames = DNAData.columns.values\n",
    "DNADataNp = DNAData.to_numpy()\n",
    "samples, labels = DNADataNp.shape\n",
    "x1 = []\n",
    "x2 = []\n",
    "labellist = []\n",
    "for label in range(0,labels,2):\n",
    "    for sample in range(samples): \n",
    "        x1.append(DNADataNp[:,label][sample])\n",
    "        x2.append(DNADataNp[:,label+1][sample])\n",
    "        labellist.append(DNANames[label+1])\n",
    "DNADataReshapeT = np.array([x1,x2])\n",
    "DNADataReshape = np.transpose(DNADataReshapeT)\n",
    "labelnp = np.transpose(np.array(labellist))\n",
    "print(DNADataReshape.shape)\n",
    "print(labelnp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "DNADataReshape.shape\n",
    "labelnp.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(DNADataReshape, labelnp, test_size=0.3, random_state= 24787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHot = y_train \n",
    "length, = OneHot.shape\n",
    "OneHotLab = []\n",
    "\n",
    "for index in range(length):\n",
    "    #print(OneHot[index])\n",
    "    if OneHot[index] == \"CYS\":\n",
    "        OneHotLab.append(0)\n",
    "    elif OneHot[index] == \"LEU\":\n",
    "        OneHotLab.append(1)\n",
    "    elif OneHot[index] == \"HIS\":\n",
    "        OneHotLab.append(2)\n",
    "    elif OneHot[index] == \"THR\":\n",
    "        OneHotLab.append(3)\n",
    "    elif OneHot[index] == \"GLN\":\n",
    "        OneHotLab.append(4)\n",
    "    elif OneHot[index] == \"MET\":\n",
    "        OneHotLab.append(5)\n",
    "    elif OneHot[index] == \"ARG\":\n",
    "        OneHotLab.append(6)\n",
    "    elif OneHot[index] == \"VAL\":\n",
    "        OneHotLab.append(7)\n",
    "    elif OneHot[index] == \"LYS\":\n",
    "        OneHotLab.append(8)\n",
    "    elif OneHot[index] == \"ALA\":\n",
    "        OneHotLab.append(9)\n",
    "    elif OneHot[index] == \"SER\":\n",
    "        OneHotLab.append(10)\n",
    "    elif OneHot[index] == \"GLU\":\n",
    "        OneHotLab.append(11)\n",
    "    elif OneHot[index] == \"GLY\":\n",
    "        OneHotLab.append(12)\n",
    "    elif OneHot[index] == \"ISO\":\n",
    "        OneHotLab.append(13)\n",
    "    elif OneHot[index] == \"TYR\":\n",
    "        OneHotLab.append(14)\n",
    "    elif OneHot[index] == \"ASN\":\n",
    "        OneHotLab.append(15)\n",
    "    elif OneHot[index] == \"PRO\":\n",
    "        OneHotLab.append(16)\n",
    "    elif OneHot[index] == \"TRP\":\n",
    "        OneHotLab.append(17)\n",
    "    elif OneHot[index] == \"PHE\":\n",
    "        OneHotLab.append(18)\n",
    "    elif OneHot[index] == \"ASP\":\n",
    "        OneHotLab.append(19)\n",
    "    else:\n",
    "        OneHotLab.append(20)\n",
    "        print(OneHot[index])\n",
    "\n",
    "Y_train = np.array(OneHotLab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OneHot = y_test \n",
    "length, = OneHot.shape\n",
    "OneHotLab = []\n",
    "\n",
    "for index in range(length):\n",
    "    #print(OneHot[index])\n",
    "    if OneHot[index] == \"CYS\":\n",
    "        OneHotLab.append(0)\n",
    "    elif OneHot[index] == \"LEU\":\n",
    "        OneHotLab.append(1)\n",
    "    elif OneHot[index] == \"HIS\":\n",
    "        OneHotLab.append(2)\n",
    "    elif OneHot[index] == \"THR\":\n",
    "        OneHotLab.append(3)\n",
    "    elif OneHot[index] == \"GLN\":\n",
    "        OneHotLab.append(4)\n",
    "    elif OneHot[index] == \"MET\":\n",
    "        OneHotLab.append(5)\n",
    "    elif OneHot[index] == \"ARG\":\n",
    "        OneHotLab.append(6)\n",
    "    elif OneHot[index] == \"VAL\":\n",
    "        OneHotLab.append(7)\n",
    "    elif OneHot[index] == \"LYS\":\n",
    "        OneHotLab.append(8)\n",
    "    elif OneHot[index] == \"ALA\":\n",
    "        OneHotLab.append(9)\n",
    "    elif OneHot[index] == \"SER\":\n",
    "        OneHotLab.append(10)\n",
    "    elif OneHot[index] == \"GLU\":\n",
    "        OneHotLab.append(11)\n",
    "    elif OneHot[index] == \"GLY\":\n",
    "        OneHotLab.append(12)\n",
    "    elif OneHot[index] == \"ISO\":\n",
    "        OneHotLab.append(13)\n",
    "    elif OneHot[index] == \"TYR\":\n",
    "        OneHotLab.append(14)\n",
    "    elif OneHot[index] == \"ASN\":\n",
    "        OneHotLab.append(15)\n",
    "    elif OneHot[index] == \"PRO\":\n",
    "        OneHotLab.append(16)\n",
    "    elif OneHot[index] == \"TRP\":\n",
    "        OneHotLab.append(17)\n",
    "    elif OneHot[index] == \"PHE\":\n",
    "        OneHotLab.append(18)\n",
    "    elif OneHot[index] == \"ASP\":\n",
    "        OneHotLab.append(19)\n",
    "    else:\n",
    "        OneHotLab.append(20)\n",
    "        print(OneHot[index])\n",
    "\n",
    "Y_test = np.array(OneHotLab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1400, 2, 1)\n",
      "(1400, 20)\n",
      "(600, 2, 1)\n",
      "(600, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 2, 1)\n",
    "print(X_train.shape)\n",
    "num_classes = 20\n",
    "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "print(Y_train.shape)\n",
    "X_test = X_test.reshape(X_test.shape[0], 2, 1)\n",
    "print(X_test.shape)\n",
    "num_classes = 20\n",
    "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
    "print(Y_test.shape)\n",
    "input_shape = (2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               600       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                4020      \n",
      "=================================================================\n",
      "Total params: 607,620\n",
      "Trainable params: 607,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Sequential model is a linear stack of layers\n",
    "input_shape = (2,1)\n",
    "num_classes= 20\n",
    "model = Sequential()\n",
    "\n",
    "# Our input is a 28 by 28 image/matrix, in implementation (28x28x1)\n",
    "model.add(InputLayer(input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 600 samples\n",
      "Epoch 1/400\n",
      "1400/1400 [==============================] - 1s 540us/step - loss: 2.9543 - accuracy: 0.0493 - val_loss: 2.7999 - val_accuracy: 0.0483\n",
      "Epoch 2/400\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 2.7814 - accuracy: 0.0821 - val_loss: 2.4868 - val_accuracy: 0.1050\n",
      "Epoch 3/400\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 2.5959 - accuracy: 0.0971 - val_loss: 2.4260 - val_accuracy: 0.1067\n",
      "Epoch 4/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 2.5220 - accuracy: 0.1186 - val_loss: 2.3273 - val_accuracy: 0.1050\n",
      "Epoch 5/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 2.3785 - accuracy: 0.1650 - val_loss: 2.1858 - val_accuracy: 0.1700\n",
      "Epoch 6/400\n",
      "1400/1400 [==============================] - 0s 53us/step - loss: 2.3503 - accuracy: 0.1664 - val_loss: 2.2356 - val_accuracy: 0.2300\n",
      "Epoch 7/400\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 2.2644 - accuracy: 0.1929 - val_loss: 2.0845 - val_accuracy: 0.2067\n",
      "Epoch 8/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 2.2031 - accuracy: 0.2264 - val_loss: 1.9669 - val_accuracy: 0.3500\n",
      "Epoch 9/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 2.0580 - accuracy: 0.2536 - val_loss: 1.8695 - val_accuracy: 0.2950\n",
      "Epoch 10/400\n",
      "1400/1400 [==============================] - 0s 50us/step - loss: 1.9217 - accuracy: 0.2814 - val_loss: 1.6612 - val_accuracy: 0.3417\n",
      "Epoch 11/400\n",
      "1400/1400 [==============================] - 0s 50us/step - loss: 1.6783 - accuracy: 0.3400 - val_loss: 1.3238 - val_accuracy: 0.5517\n",
      "Epoch 12/400\n",
      "1400/1400 [==============================] - 0s 50us/step - loss: 1.8141 - accuracy: 0.3193 - val_loss: 1.9035 - val_accuracy: 0.3217\n",
      "Epoch 13/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 1.9857 - accuracy: 0.3014 - val_loss: 1.7606 - val_accuracy: 0.3017\n",
      "Epoch 14/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.8465 - accuracy: 0.3243 - val_loss: 1.6699 - val_accuracy: 0.3983\n",
      "Epoch 15/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.7087 - accuracy: 0.3750 - val_loss: 1.3766 - val_accuracy: 0.4633\n",
      "Epoch 16/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 1.6554 - accuracy: 0.3671 - val_loss: 1.3935 - val_accuracy: 0.5083\n",
      "Epoch 17/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.4672 - accuracy: 0.4307 - val_loss: 1.1439 - val_accuracy: 0.4967\n",
      "Epoch 18/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.3391 - accuracy: 0.4693 - val_loss: 1.0156 - val_accuracy: 0.5783\n",
      "Epoch 19/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 1.2915 - accuracy: 0.5071 - val_loss: 0.9936 - val_accuracy: 0.5683\n",
      "Epoch 20/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 1.1155 - accuracy: 0.5379 - val_loss: 0.8751 - val_accuracy: 0.6967\n",
      "Epoch 21/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 1.0146 - accuracy: 0.5943 - val_loss: 0.7415 - val_accuracy: 0.7383\n",
      "Epoch 22/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 1.0732 - accuracy: 0.5850 - val_loss: 0.7813 - val_accuracy: 0.7050\n",
      "Epoch 23/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.8834 - accuracy: 0.6479 - val_loss: 0.6849 - val_accuracy: 0.7400\n",
      "Epoch 24/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.6140 - accuracy: 0.5529 - val_loss: 2.3142 - val_accuracy: 0.3817\n",
      "Epoch 25/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.9064 - accuracy: 0.3736 - val_loss: 1.5923 - val_accuracy: 0.3933\n",
      "Epoch 26/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 1.5851 - accuracy: 0.4293 - val_loss: 1.3500 - val_accuracy: 0.4600\n",
      "Epoch 27/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.4539 - accuracy: 0.4429 - val_loss: 1.2553 - val_accuracy: 0.4533\n",
      "Epoch 28/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 1.3240 - accuracy: 0.4650 - val_loss: 1.1520 - val_accuracy: 0.4933\n",
      "Epoch 29/400\n",
      "1400/1400 [==============================] - 0s 50us/step - loss: 1.1865 - accuracy: 0.5121 - val_loss: 1.0071 - val_accuracy: 0.5783\n",
      "Epoch 30/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.0096 - accuracy: 0.5857 - val_loss: 0.8244 - val_accuracy: 0.5850\n",
      "Epoch 31/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.8955 - accuracy: 0.6250 - val_loss: 0.8599 - val_accuracy: 0.6433\n",
      "Epoch 32/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 1.0154 - accuracy: 0.5729 - val_loss: 0.7542 - val_accuracy: 0.7083\n",
      "Epoch 33/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 1.0664 - accuracy: 0.5414 - val_loss: 0.7957 - val_accuracy: 0.7167\n",
      "Epoch 34/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.8880 - accuracy: 0.6493 - val_loss: 0.7683 - val_accuracy: 0.7617\n",
      "Epoch 35/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.7342 - accuracy: 0.6871 - val_loss: 0.5753 - val_accuracy: 0.7667\n",
      "Epoch 36/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.6607 - accuracy: 0.7193 - val_loss: 0.5312 - val_accuracy: 0.7867\n",
      "Epoch 37/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.6082 - accuracy: 0.7221 - val_loss: 0.7116 - val_accuracy: 0.6283\n",
      "Epoch 38/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.7026 - accuracy: 0.6936 - val_loss: 0.5533 - val_accuracy: 0.8533\n",
      "Epoch 39/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.6453 - accuracy: 0.7257 - val_loss: 0.5423 - val_accuracy: 0.7400\n",
      "Epoch 40/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.5981 - accuracy: 0.7329 - val_loss: 0.6008 - val_accuracy: 0.7167\n",
      "Epoch 41/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.5836 - accuracy: 0.7464 - val_loss: 0.5303 - val_accuracy: 0.7833\n",
      "Epoch 42/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.5409 - accuracy: 0.7621 - val_loss: 0.4729 - val_accuracy: 0.7817\n",
      "Epoch 43/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.5525 - accuracy: 0.7621 - val_loss: 0.4682 - val_accuracy: 0.8483\n",
      "Epoch 44/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.5188 - accuracy: 0.7764 - val_loss: 0.4003 - val_accuracy: 0.8217\n",
      "Epoch 45/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.5192 - accuracy: 0.7679 - val_loss: 0.5315 - val_accuracy: 0.7217\n",
      "Epoch 46/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.5269 - accuracy: 0.7529 - val_loss: 0.4884 - val_accuracy: 0.8050\n",
      "Epoch 47/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.5005 - accuracy: 0.7721 - val_loss: 0.4409 - val_accuracy: 0.8317\n",
      "Epoch 48/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.4561 - accuracy: 0.8093 - val_loss: 0.3840 - val_accuracy: 0.8550\n",
      "Epoch 49/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.4183 - accuracy: 0.8257 - val_loss: 0.3396 - val_accuracy: 0.9050\n",
      "Epoch 50/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4353 - accuracy: 0.8079 - val_loss: 0.3550 - val_accuracy: 0.8683\n",
      "Epoch 51/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.4238 - accuracy: 0.8171 - val_loss: 0.3190 - val_accuracy: 0.8917\n",
      "Epoch 52/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.3792 - accuracy: 0.8379 - val_loss: 0.3713 - val_accuracy: 0.8400\n",
      "Epoch 53/400\n",
      "1400/1400 [==============================] - 0s 82us/step - loss: 0.6350 - accuracy: 0.7300 - val_loss: 0.8358 - val_accuracy: 0.6533\n",
      "Epoch 54/400\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 0.7277 - accuracy: 0.7121 - val_loss: 0.5088 - val_accuracy: 0.7700\n",
      "Epoch 55/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.5289 - accuracy: 0.7907 - val_loss: 0.4743 - val_accuracy: 0.8633\n",
      "Epoch 56/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.4995 - accuracy: 0.8043 - val_loss: 0.3546 - val_accuracy: 0.9033\n",
      "Epoch 57/400\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.4621 - accuracy: 0.8129 - val_loss: 0.4021 - val_accuracy: 0.8217\n",
      "Epoch 58/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4064 - accuracy: 0.8171 - val_loss: 0.3660 - val_accuracy: 0.8183\n",
      "Epoch 59/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4223 - accuracy: 0.8036 - val_loss: 0.4669 - val_accuracy: 0.7800\n",
      "Epoch 60/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4351 - accuracy: 0.8100 - val_loss: 0.3175 - val_accuracy: 0.8783\n",
      "Epoch 61/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.4333 - accuracy: 0.8121 - val_loss: 0.3664 - val_accuracy: 0.8417\n",
      "Epoch 62/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4123 - accuracy: 0.8221 - val_loss: 0.3564 - val_accuracy: 0.8383\n",
      "Epoch 63/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.4378 - accuracy: 0.7971 - val_loss: 0.3545 - val_accuracy: 0.8700\n",
      "Epoch 64/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.4075 - accuracy: 0.8264 - val_loss: 0.3471 - val_accuracy: 0.8950\n",
      "Epoch 65/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.3496 - accuracy: 0.8700 - val_loss: 0.2966 - val_accuracy: 0.8817\n",
      "Epoch 66/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.3353 - accuracy: 0.8621 - val_loss: 0.2913 - val_accuracy: 0.9017\n",
      "Epoch 67/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.4128 - accuracy: 0.8150 - val_loss: 0.3706 - val_accuracy: 0.8617\n",
      "Epoch 68/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.3667 - accuracy: 0.8364 - val_loss: 0.3313 - val_accuracy: 0.8600\n",
      "Epoch 69/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.3772 - accuracy: 0.8407 - val_loss: 0.2869 - val_accuracy: 0.9083\n",
      "Epoch 70/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.3545 - accuracy: 0.8707 - val_loss: 0.3121 - val_accuracy: 0.8283\n",
      "Epoch 71/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.4077 - accuracy: 0.8129 - val_loss: 0.3166 - val_accuracy: 0.8333\n",
      "Epoch 72/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.3476 - accuracy: 0.8457 - val_loss: 0.2614 - val_accuracy: 0.8867\n",
      "Epoch 73/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.3311 - accuracy: 0.8529 - val_loss: 0.3020 - val_accuracy: 0.8633\n",
      "Epoch 74/400\n",
      "1400/1400 [==============================] - 0s 53us/step - loss: 0.3556 - accuracy: 0.8507 - val_loss: 0.2508 - val_accuracy: 0.9133\n",
      "Epoch 75/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.3236 - accuracy: 0.8693 - val_loss: 0.2718 - val_accuracy: 0.8967\n",
      "Epoch 76/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.2939 - accuracy: 0.8729 - val_loss: 0.2617 - val_accuracy: 0.9000\n",
      "Epoch 77/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.3300 - accuracy: 0.8529 - val_loss: 0.3670 - val_accuracy: 0.8483\n",
      "Epoch 78/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.3202 - accuracy: 0.8664 - val_loss: 0.3732 - val_accuracy: 0.8317\n",
      "Epoch 79/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.3528 - accuracy: 0.8329 - val_loss: 0.2547 - val_accuracy: 0.9100\n",
      "Epoch 80/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.2979 - accuracy: 0.8714 - val_loss: 0.3263 - val_accuracy: 0.8467\n",
      "Epoch 81/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.3097 - accuracy: 0.8629 - val_loss: 0.2932 - val_accuracy: 0.8567\n",
      "Epoch 82/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.2916 - accuracy: 0.8757 - val_loss: 0.2144 - val_accuracy: 0.9550\n",
      "Epoch 83/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.2652 - accuracy: 0.8971 - val_loss: 0.2700 - val_accuracy: 0.8867\n",
      "Epoch 84/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.3065 - accuracy: 0.8700 - val_loss: 0.2535 - val_accuracy: 0.9017\n",
      "Epoch 85/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.2544 - accuracy: 0.9136 - val_loss: 0.2147 - val_accuracy: 0.9467\n",
      "Epoch 86/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.2174 - accuracy: 0.9221 - val_loss: 0.2033 - val_accuracy: 0.9400\n",
      "Epoch 87/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.2314 - accuracy: 0.9129 - val_loss: 0.3413 - val_accuracy: 0.8567\n",
      "Epoch 88/400\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 0.3389 - accuracy: 0.8714 - val_loss: 0.2710 - val_accuracy: 0.8950\n",
      "Epoch 89/400\n",
      "1400/1400 [==============================] - 0s 54us/step - loss: 0.4951 - accuracy: 0.7864 - val_loss: 0.3243 - val_accuracy: 0.8650\n",
      "Epoch 90/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.5157 - accuracy: 0.7843 - val_loss: 0.3461 - val_accuracy: 0.8883\n",
      "Epoch 91/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.5049 - accuracy: 0.8093 - val_loss: 0.5312 - val_accuracy: 0.7667\n",
      "Epoch 92/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.4223 - accuracy: 0.8314 - val_loss: 0.3214 - val_accuracy: 0.9133\n",
      "Epoch 93/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.3581 - accuracy: 0.8500 - val_loss: 0.2916 - val_accuracy: 0.8850\n",
      "Epoch 94/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.3405 - accuracy: 0.8571 - val_loss: 0.2615 - val_accuracy: 0.9167\n",
      "Epoch 95/400\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 0.2961 - accuracy: 0.8871 - val_loss: 0.2475 - val_accuracy: 0.9117\n",
      "Epoch 96/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.2614 - accuracy: 0.8900 - val_loss: 0.1935 - val_accuracy: 0.9417\n",
      "Epoch 97/400\n",
      "1400/1400 [==============================] - 0s 74us/step - loss: 0.2316 - accuracy: 0.9107 - val_loss: 0.2229 - val_accuracy: 0.9433\n",
      "Epoch 98/400\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.2764 - accuracy: 0.9029 - val_loss: 0.1914 - val_accuracy: 0.9350\n",
      "Epoch 99/400\n",
      "1400/1400 [==============================] - 0s 52us/step - loss: 0.2939 - accuracy: 0.8779 - val_loss: 0.2338 - val_accuracy: 0.8983\n",
      "Epoch 100/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.2729 - accuracy: 0.8929 - val_loss: 0.1605 - val_accuracy: 0.9450\n",
      "Epoch 101/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.2977 - accuracy: 0.8843 - val_loss: 0.2213 - val_accuracy: 0.8850\n",
      "Epoch 102/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.2610 - accuracy: 0.8914 - val_loss: 0.2527 - val_accuracy: 0.8917\n",
      "Epoch 103/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.3395 - accuracy: 0.8536 - val_loss: 0.2796 - val_accuracy: 0.8917\n",
      "Epoch 104/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.3141 - accuracy: 0.8700 - val_loss: 0.2145 - val_accuracy: 0.9150\n",
      "Epoch 105/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2665 - accuracy: 0.9143 - val_loss: 0.2318 - val_accuracy: 0.9350\n",
      "Epoch 106/400\n",
      "1400/1400 [==============================] - 0s 47us/step - loss: 0.2549 - accuracy: 0.9043 - val_loss: 0.2102 - val_accuracy: 0.9267\n",
      "Epoch 107/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2299 - accuracy: 0.9057 - val_loss: 0.1699 - val_accuracy: 0.9350\n",
      "Epoch 108/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2331 - accuracy: 0.9050 - val_loss: 0.4377 - val_accuracy: 0.8233\n",
      "Epoch 109/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.3444 - accuracy: 0.8621 - val_loss: 0.2597 - val_accuracy: 0.9117\n",
      "Epoch 110/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4718 - accuracy: 0.8193 - val_loss: 0.6344 - val_accuracy: 0.7233\n",
      "Epoch 111/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.4590 - accuracy: 0.7929 - val_loss: 0.3469 - val_accuracy: 0.8767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3544 - accuracy: 0.8429 - val_loss: 0.2471 - val_accuracy: 0.9067\n",
      "Epoch 113/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3339 - accuracy: 0.8550 - val_loss: 0.2490 - val_accuracy: 0.9217\n",
      "Epoch 114/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2825 - accuracy: 0.8929 - val_loss: 0.2267 - val_accuracy: 0.8933\n",
      "Epoch 115/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2388 - accuracy: 0.9043 - val_loss: 0.1934 - val_accuracy: 0.9100\n",
      "Epoch 116/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.2175 - accuracy: 0.9214 - val_loss: 0.1782 - val_accuracy: 0.9417\n",
      "Epoch 117/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2258 - accuracy: 0.9136 - val_loss: 0.3811 - val_accuracy: 0.8650\n",
      "Epoch 118/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3219 - accuracy: 0.8843 - val_loss: 0.1767 - val_accuracy: 0.9483\n",
      "Epoch 119/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2748 - accuracy: 0.8871 - val_loss: 0.2023 - val_accuracy: 0.9267\n",
      "Epoch 120/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2649 - accuracy: 0.8986 - val_loss: 0.2059 - val_accuracy: 0.9250\n",
      "Epoch 121/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2118 - accuracy: 0.9257 - val_loss: 0.1699 - val_accuracy: 0.9400\n",
      "Epoch 122/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2071 - accuracy: 0.9236 - val_loss: 0.1611 - val_accuracy: 0.9483\n",
      "Epoch 123/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.1868 - accuracy: 0.9364 - val_loss: 0.1454 - val_accuracy: 0.9517\n",
      "Epoch 124/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.2109 - accuracy: 0.9207 - val_loss: 0.3555 - val_accuracy: 0.8700\n",
      "Epoch 125/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3110 - accuracy: 0.8736 - val_loss: 0.4692 - val_accuracy: 0.8150\n",
      "Epoch 126/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.4099 - accuracy: 0.8136 - val_loss: 0.2864 - val_accuracy: 0.8717\n",
      "Epoch 127/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.3335 - accuracy: 0.8564 - val_loss: 0.3066 - val_accuracy: 0.8283\n",
      "Epoch 128/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3273 - accuracy: 0.8371 - val_loss: 0.2095 - val_accuracy: 0.9317\n",
      "Epoch 129/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2522 - accuracy: 0.9071 - val_loss: 0.1988 - val_accuracy: 0.9317\n",
      "Epoch 130/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.2350 - accuracy: 0.9086 - val_loss: 0.1655 - val_accuracy: 0.9467\n",
      "Epoch 131/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2113 - accuracy: 0.9214 - val_loss: 0.1618 - val_accuracy: 0.9433\n",
      "Epoch 132/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2099 - accuracy: 0.9157 - val_loss: 0.1597 - val_accuracy: 0.9417\n",
      "Epoch 133/400\n",
      "1400/1400 [==============================] - 0s 51us/step - loss: 0.2039 - accuracy: 0.9186 - val_loss: 0.1444 - val_accuracy: 0.9500\n",
      "Epoch 134/400\n",
      "1400/1400 [==============================] - 0s 57us/step - loss: 0.1891 - accuracy: 0.9364 - val_loss: 0.1450 - val_accuracy: 0.9483\n",
      "Epoch 135/400\n",
      "1400/1400 [==============================] - 0s 61us/step - loss: 0.2195 - accuracy: 0.9250 - val_loss: 0.2139 - val_accuracy: 0.9017\n",
      "Epoch 136/400\n",
      "1400/1400 [==============================] - 0s 57us/step - loss: 0.4054 - accuracy: 0.8336 - val_loss: 0.5907 - val_accuracy: 0.7483\n",
      "Epoch 137/400\n",
      "1400/1400 [==============================] - 0s 54us/step - loss: 0.3786 - accuracy: 0.8514 - val_loss: 0.4190 - val_accuracy: 0.8617\n",
      "Epoch 138/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.3321 - accuracy: 0.8643 - val_loss: 0.2260 - val_accuracy: 0.9150\n",
      "Epoch 139/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3187 - accuracy: 0.8757 - val_loss: 0.2418 - val_accuracy: 0.9000\n",
      "Epoch 140/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3062 - accuracy: 0.8586 - val_loss: 0.2504 - val_accuracy: 0.8933\n",
      "Epoch 141/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2870 - accuracy: 0.8771 - val_loss: 0.2279 - val_accuracy: 0.9150\n",
      "Epoch 142/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2504 - accuracy: 0.9014 - val_loss: 0.2052 - val_accuracy: 0.8967\n",
      "Epoch 143/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2609 - accuracy: 0.8879 - val_loss: 0.2191 - val_accuracy: 0.9167\n",
      "Epoch 144/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.3315 - accuracy: 0.8693 - val_loss: 0.2765 - val_accuracy: 0.8933\n",
      "Epoch 145/400\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 0.2805 - accuracy: 0.8871 - val_loss: 0.1880 - val_accuracy: 0.9350\n",
      "Epoch 146/400\n",
      "1400/1400 [==============================] - 0s 57us/step - loss: 0.2488 - accuracy: 0.9100 - val_loss: 0.1700 - val_accuracy: 0.9450\n",
      "Epoch 147/400\n",
      "1400/1400 [==============================] - 0s 53us/step - loss: 0.2242 - accuracy: 0.9171 - val_loss: 0.1808 - val_accuracy: 0.9317\n",
      "Epoch 148/400\n",
      "1400/1400 [==============================] - 0s 66us/step - loss: 0.1948 - accuracy: 0.9321 - val_loss: 0.1433 - val_accuracy: 0.9517\n",
      "Epoch 149/400\n",
      "1400/1400 [==============================] - 0s 59us/step - loss: 0.1901 - accuracy: 0.9271 - val_loss: 0.2166 - val_accuracy: 0.8883\n",
      "Epoch 150/400\n",
      "1400/1400 [==============================] - 0s 63us/step - loss: 0.2703 - accuracy: 0.8879 - val_loss: 0.1959 - val_accuracy: 0.9333\n",
      "Epoch 151/400\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 0.3556 - accuracy: 0.8721 - val_loss: 0.3925 - val_accuracy: 0.8567\n",
      "Epoch 152/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3490 - accuracy: 0.8521 - val_loss: 0.5441 - val_accuracy: 0.8117\n",
      "Epoch 153/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3483 - accuracy: 0.8643 - val_loss: 0.3008 - val_accuracy: 0.8533\n",
      "Epoch 154/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.3021 - accuracy: 0.8636 - val_loss: 0.2701 - val_accuracy: 0.8733\n",
      "Epoch 155/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2696 - accuracy: 0.8871 - val_loss: 0.2616 - val_accuracy: 0.9117\n",
      "Epoch 156/400\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 0.2229 - accuracy: 0.9157 - val_loss: 0.1845 - val_accuracy: 0.9467\n",
      "Epoch 157/400\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.2070 - accuracy: 0.9193 - val_loss: 0.1601 - val_accuracy: 0.9533\n",
      "Epoch 158/400\n",
      "1400/1400 [==============================] - 0s 55us/step - loss: 0.2050 - accuracy: 0.9236 - val_loss: 0.2487 - val_accuracy: 0.8867\n",
      "Epoch 159/400\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.2127 - accuracy: 0.9179 - val_loss: 0.1710 - val_accuracy: 0.9367\n",
      "Epoch 160/400\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.1855 - accuracy: 0.9264 - val_loss: 0.1509 - val_accuracy: 0.9500\n",
      "Epoch 161/400\n",
      "1400/1400 [==============================] - 0s 53us/step - loss: 0.1702 - accuracy: 0.9414 - val_loss: 0.1439 - val_accuracy: 0.9433\n",
      "Epoch 162/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.1969 - accuracy: 0.9171 - val_loss: 0.1807 - val_accuracy: 0.9117\n",
      "Epoch 163/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2275 - accuracy: 0.9029 - val_loss: 0.2064 - val_accuracy: 0.9100\n",
      "Epoch 164/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3040 - accuracy: 0.8821 - val_loss: 0.4240 - val_accuracy: 0.8450\n",
      "Epoch 165/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4663 - accuracy: 0.8571 - val_loss: 0.4063 - val_accuracy: 0.8450\n",
      "Epoch 166/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.3221 - accuracy: 0.8586 - val_loss: 0.2299 - val_accuracy: 0.9050\n",
      "Epoch 167/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2757 - accuracy: 0.8857 - val_loss: 0.2094 - val_accuracy: 0.9233\n",
      "Epoch 168/400\n",
      "1400/1400 [==============================] - 0s 48us/step - loss: 0.2445 - accuracy: 0.9150 - val_loss: 0.1629 - val_accuracy: 0.9583\n",
      "Epoch 169/400\n",
      "1400/1400 [==============================] - 0s 49us/step - loss: 0.2185 - accuracy: 0.9207 - val_loss: 0.1703 - val_accuracy: 0.9517\n",
      "Epoch 170/400\n",
      "1400/1400 [==============================] - 0s 56us/step - loss: 0.2307 - accuracy: 0.9143 - val_loss: 0.1879 - val_accuracy: 0.9400\n",
      "Epoch 171/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.2084 - accuracy: 0.9143 - val_loss: 0.1608 - val_accuracy: 0.9433\n",
      "Epoch 172/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2039 - accuracy: 0.9193 - val_loss: 0.1622 - val_accuracy: 0.9400\n",
      "Epoch 173/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.1876 - accuracy: 0.9364 - val_loss: 0.1440 - val_accuracy: 0.9683\n",
      "Epoch 174/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.1808 - accuracy: 0.9429 - val_loss: 0.1502 - val_accuracy: 0.9283\n",
      "Epoch 175/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.1777 - accuracy: 0.9321 - val_loss: 0.1639 - val_accuracy: 0.9367\n",
      "Epoch 176/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2473 - accuracy: 0.9007 - val_loss: 0.2041 - val_accuracy: 0.9167\n",
      "Epoch 177/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3103 - accuracy: 0.8700 - val_loss: 0.2556 - val_accuracy: 0.8767\n",
      "Epoch 178/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2912 - accuracy: 0.8807 - val_loss: 0.3012 - val_accuracy: 0.8433\n",
      "Epoch 179/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.3480 - accuracy: 0.8550 - val_loss: 0.2080 - val_accuracy: 0.9133\n",
      "Epoch 180/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.3299 - accuracy: 0.8779 - val_loss: 0.3453 - val_accuracy: 0.8850\n",
      "Epoch 181/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4540 - accuracy: 0.8443 - val_loss: 0.6535 - val_accuracy: 0.8150\n",
      "Epoch 182/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4405 - accuracy: 0.8143 - val_loss: 0.3197 - val_accuracy: 0.8467\n",
      "Epoch 183/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.3114 - accuracy: 0.8736 - val_loss: 0.2395 - val_accuracy: 0.8733\n",
      "Epoch 184/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2447 - accuracy: 0.8986 - val_loss: 0.2111 - val_accuracy: 0.9117\n",
      "Epoch 185/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2420 - accuracy: 0.9036 - val_loss: 0.2669 - val_accuracy: 0.9017\n",
      "Epoch 186/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2307 - accuracy: 0.9121 - val_loss: 0.1674 - val_accuracy: 0.9517\n",
      "Epoch 187/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2227 - accuracy: 0.9207 - val_loss: 0.3684 - val_accuracy: 0.8750\n",
      "Epoch 188/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.3002 - accuracy: 0.8871 - val_loss: 0.2393 - val_accuracy: 0.9083\n",
      "Epoch 189/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2499 - accuracy: 0.9000 - val_loss: 0.2315 - val_accuracy: 0.8750\n",
      "Epoch 190/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.2228 - accuracy: 0.9079 - val_loss: 0.1650 - val_accuracy: 0.9400\n",
      "Epoch 191/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2051 - accuracy: 0.9286 - val_loss: 0.1569 - val_accuracy: 0.9450\n",
      "Epoch 192/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2069 - accuracy: 0.9179 - val_loss: 0.2210 - val_accuracy: 0.9150\n",
      "Epoch 193/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2426 - accuracy: 0.9064 - val_loss: 0.1616 - val_accuracy: 0.9383\n",
      "Epoch 194/400\n",
      "1400/1400 [==============================] - 0s 46us/step - loss: 0.3186 - accuracy: 0.8929 - val_loss: 0.4756 - val_accuracy: 0.8033\n",
      "Epoch 195/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.6421 - accuracy: 0.7993 - val_loss: 0.3953 - val_accuracy: 0.8283\n",
      "Epoch 196/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.4925 - accuracy: 0.7914 - val_loss: 0.5110 - val_accuracy: 0.7767\n",
      "Epoch 197/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4531 - accuracy: 0.8329 - val_loss: 0.3143 - val_accuracy: 0.8850\n",
      "Epoch 198/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4062 - accuracy: 0.8386 - val_loss: 0.2473 - val_accuracy: 0.9317\n",
      "Epoch 199/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.3107 - accuracy: 0.8843 - val_loss: 0.2296 - val_accuracy: 0.9383\n",
      "Epoch 200/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2638 - accuracy: 0.8957 - val_loss: 0.2587 - val_accuracy: 0.9133\n",
      "Epoch 201/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2281 - accuracy: 0.9064 - val_loss: 0.1870 - val_accuracy: 0.9417\n",
      "Epoch 202/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2145 - accuracy: 0.9171 - val_loss: 0.1960 - val_accuracy: 0.9183\n",
      "Epoch 203/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2006 - accuracy: 0.9250 - val_loss: 0.1788 - val_accuracy: 0.9383\n",
      "Epoch 204/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2540 - accuracy: 0.9021 - val_loss: 0.2856 - val_accuracy: 0.8900\n",
      "Epoch 205/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.3471 - accuracy: 0.8650 - val_loss: 0.3477 - val_accuracy: 0.8617\n",
      "Epoch 206/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.3362 - accuracy: 0.8471 - val_loss: 0.6497 - val_accuracy: 0.8217\n",
      "Epoch 207/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.4022 - accuracy: 0.8393 - val_loss: 0.2932 - val_accuracy: 0.8800\n",
      "Epoch 208/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2907 - accuracy: 0.8764 - val_loss: 0.2200 - val_accuracy: 0.8883\n",
      "Epoch 209/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2540 - accuracy: 0.8914 - val_loss: 0.1939 - val_accuracy: 0.8983\n",
      "Epoch 210/400\n",
      "1400/1400 [==============================] - 0s 44us/step - loss: 0.2154 - accuracy: 0.9114 - val_loss: 0.1908 - val_accuracy: 0.9317\n",
      "Epoch 211/400\n",
      "1400/1400 [==============================] - 0s 45us/step - loss: 0.2003 - accuracy: 0.9157 - val_loss: 0.1774 - val_accuracy: 0.9383\n",
      "600/600 [==============================] - 0s 38us/step\n",
      "Test loss: 0.1773594323794047\n",
      "Test accuracy: 0.9383333325386047\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "batch_size = 200\n",
    "epochs = 400\n",
    "# train network by calling fit function\n",
    "history = model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,callbacks=[callback],\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "# evaluate the accuracy of trained model using the testing data\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'])\n",
    "x = np.array(range(0,250))\n",
    "y = np.ones(250)*0.85\n",
    "plt.plot(x,y,c=\"red\",label=\"85% Test Accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.1773594323794047\n",
      "Test accuracy: 0.9383333325386047\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
